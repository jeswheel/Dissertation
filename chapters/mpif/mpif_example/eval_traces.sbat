#!/bin/bash
# Created by the ARC-TS SLURM job script generator for use on Great Lakes
# Thu Apr 14 2022 10:24:48 GMT-0400 (EDT)

# The name of the job:
#SBATCH --job-name="measlesPOMP search"

# Send yourself an email when the job:
# aborts abnormally (fails)
#SBATCH --mail-type=FAIL
# ends successfully
#SBATCH --mail-type=END

# Use this email address:
#SBATCH --mail-user=aaronabk@umich.edu

# Maximum number of tasks/CPU cores used by the job:
#SBATCH --nodes=1
# ntasks is the important one
#SBATCH --ntasks-per-node=36
#SBATCH --cpus-per-task=1

# Total memory allocated for the job:
## 5GB/cpu is the basic share
#SBATCH --mem-per-cpu=2GB

# The maximum running time of the job in days-hours:mins:sec
#SBATCH --time=0-12:00:00

# The account which this job should run under:
#SBATCH --account="ionides0"

# Partition for the job:
#SBATCH -p standard

# Array job ID's
# These should also be the iteration numbers we're evaluating
#SBATCH --array=20,56,92,128,164
# --array=1,2

# Run from project root
cd $proj_root

# The modules to load:
module load R/4.4.0

# The job command(s):
echo "Running on $SLURM_JOB_NODELIST"
echo "Running in $(pwd)"
echo "Running with $np particles"
echo "Running with $mod model"
echo "Running with $fitr method"
 
## Important variables ##
# out_dir must end with /
export out_dir=$parent_dir/evals/iter_$SLURM_ARRAY_TASK_ID/
R_file="eval_traces.R"

### Main commands ###
echo "Making directory $out_dir"
mkdir -p $out_dir
echo "Running $wksp_rt/$R_file"
R CMD BATCH --no-restore --no-save \
  $wksp_rt/$R_file $out_dir/$R_file"out"

