\chapter{Iterating Marginalized Bayes Maps for Likelihood Maximization}
\label{chpt:mpif}

<<MPIFSetup, include=FALSE,echo=FALSE,results='hide'>>=
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.align = 'center',
  dev = 'cairo_pdf'
)

library(knitr)       # Necessary for Rnw file
library(tidyverse)
library(panelPomp)        # Used for the bake function
library(latex2exp)
source("mpif_example/functions.R")

# Setting black and white ggplot2 theme for entire document.
theme_set(
  theme_bw() +
    theme(
      plot.title = element_text(hjust = 0.5)
    )
)

calculate_ellipse <- function(mu, sigma) {
  radius <- sqrt(2 * stats::qf(0.95, 2, Inf))
  inner <- function(i) {
    chol_decomp <- chol(sigma[[i]])
    angles <- (0:100) * 2 * pi / 100
    unit.circle <- cbind(cos(angles), sin(angles))
    ellipse <- t(mu[i, ] + radius * t(unit.circle %*% chol_decomp))
    ellipse <- as.data.frame(ellipse)
    colnames(ellipse) <- c("X1","X2")
    ellipse$group <- i
    ellipse
  }
  do.call(rbind, purrr::map(1:length(sigma), inner))
}

MARG_COLS <- c("#c05502", "#178a68")

#' Gaussian-Gaussian, single unit, data cloning algorithm.
#'
#' This function performs data-cloning on the special case with Gaussian
#' likelihood and prior, with the MLE centered at zero.
#'
#' @param Lambda Covariance matrix of likelihood.
#' @param Prior Prior distribution for parameters.
#' @param M Number of iterations.
#'
#' @return
GG_DC <- function(Lambda, Prior, M) {

  is_pd <- matrixcalc::is.positive.definite(
    Lambda
  )

  if (!is_pd) stop("Lambda must be a postive definite matrix")

  # A single step of the data cloning algorithm
  DC_update <- function(prior) {
    new_precision <- prior$precision + Lambda
    new_mean <- solve(new_precision) %*% (prior$precision %*% prior$mean)

    new_prior <- list(
      'mean' = new_mean,
      'precision' = new_precision
    )
    new_prior
  }

  all_DC_dists <- list()
  all_DC_dists[[1]] <- Prior

  priorDC <- Prior

  for (i in 1:M) {
    priorDC <- DC_update(priorDC)
    all_DC_dists[[i + 1]] <- priorDC
  }

  all_DC_dists
}

#' Gaussian-Gaussian, single unit, perturbed data cloning algorithm.
#'
#' This function performs perturbed data-cloning on the special case with Gaussian
#' likelihood and prior, with the MLE centered at zero.
#'
#' @param Lambda Covariance matrix of likelihood.
#' @param Prior Prior distribution for parameters.
#' @param M Number of iterations.
#'
#' @return
GG_PDC <- function(Lambda, Prior, M, init_noise = 1/4) {

  is_pd <- matrixcalc::is.positive.definite(
    Lambda
  )

  if (!is_pd) stop("Lambda must be a postive definite matrix")

  # A single step of the data cloning algorithm
  PDC_update <- function(prior, m, tau0 = 1/init_noise) {

    # Goes to infinity quite fast (i.e., the variance goes to zero fast)
    var_eps <- diag(1 / (tau0 * m), nrow = 2, ncol = 2)
    tmp_prior <- prior

    # Add random noise to prior, with variance 1 / (tau0 * m^2) -> 0
    tmp_prior$precision <- solve(solve(prior$precision) + var_eps)

    # Now do DC.
    new_precision <- tmp_prior$precision + Lambda
    new_mean <- solve(new_precision) %*% (tmp_prior$precision %*% tmp_prior$mean)

    new_prior <- list(
      'mean' = new_mean,
      'precision' = new_precision
    )
    new_prior
  }

  all_DC_dists <- list()
  all_DC_dists[[1]] <- Prior

  priorDC <- Prior

  for (i in 1:M) {
    priorDC <- PDC_update(priorDC, m = i, tau0 = 1/init_noise)
    all_DC_dists[[i + 1]] <- priorDC
  }

  all_DC_dists
}

#' Gaussian-Gaussian, single unit, marginalized data cloning algorithm.
#'
#' This function performs marginalized data-cloning on the special case with
#' Gaussian likelihood and prior, with the MLE centered at zero.
#'
#' @param Lambda Covariance matrix of likelihood.
#' @param Prior Prior distribution for parameters.
#' @param M Number of iterations.
#'
#' @return
GG_MDC <- function(Lambda, Prior, M) {

  prior <- Prior

  is_pd <- matrixcalc::is.positive.definite(
    Lambda
  )

  if (!is_pd) stop("Lambda must be a postive definite matrix")

  all_MDC_dists <- list()
  all_MDC_dists[[1]] <- prior

  for (i in 1:M) {
    prior <- all_MDC_dists[[i]]
    # prior$precision <- diag(diag(prior$precision))
    new_prior <- GG_DC(Lambda, prior, 1)[[2]]
    new_prior$precision <- diag(diag(new_prior$precision))
    all_MDC_dists[[i+1]] <- new_prior
    # prior <- all_MDC_dists[[i+1]]
  }
  all_MDC_dists
}

GG_PMDC <- function(Lambda, Prior, M, init_noise = 1/4) {

  prior <- Prior

  is_pd <- matrixcalc::is.positive.definite(
    Lambda
  )

  if (!is_pd) stop("Lambda must be a postive definite matrix")

  all_MDC_dists <- list()
  all_MDC_dists[[1]] <- prior

  for (i in 1:M) {
    prior <- all_MDC_dists[[i]]

    # Goes to infinity quite fast (i.e., the variance goes to zero fast)
    var_eps <- diag(init_noise / i, nrow = 2, ncol = 2)
    tmp_prior <- prior

    # Add random noise to prior, with variance 1 / (tau0 * m^2) -> 0
    tmp_prior$precision <- solve(solve(prior$precision) + var_eps)

    # prior$precision <- diag(diag(prior$precision))
    new_prior <- GG_DC(Lambda, tmp_prior, 1)[[2]]
    new_prior$precision <- diag(diag(new_prior$precision))
    all_MDC_dists[[i+1]] <- new_prior
    # prior <- all_MDC_dists[[i+1]]
  }
  all_MDC_dists
}
@

\AtBeginEnvironment{algorithm}{%
  \singlespacing
  % \renewcommand{\arraystretch}{1}%
}

\section{Introduction}
\label{sec:mpifintro}

Panel data, otherwise known as longitudinal data, are are a collection of related time series.
Each time series is a measurement on a person, animal or object known as the {\it unit}.
A unit may have its treatment assigned via a randomized experiment, or it may be measured in an observational study.
The measurement on each unit at each observation time may be vector-valued.
While each time series within a panel dataset could be analyzed individually, there may be advantage to analyzing the entire collection of time series simultaneously.
For example, data from multiple measurement units during an infectious disease outbreak may reveal transmission dynamics not evident from individual units \citep{wiens14,ranjeva19}.
Other examples include ecological experiments and observational studies in which data are collected over time across multiple study sites (or plots within a study site) that may experience variation in covariates of interest \citep{searle16,hewitt24}.
Modeling the data collectively, rather than individually for each unit, allows for researchers to learn about processes that are shared across units, as well as identifying traits that are unique to each unit.

A common approach to modeling nonlinear dynamic systems is through the use of mechanistic models \citep{auger21}.
These models involve the proposal of a system of equations that describe how the dynamic system state evolves stochastically over time.
When combined with a model relating the state to observable quantities, we obtain a POMP model, described in Chapter~\ref{chpt:intro}.
Once calibrated to data, such models provide a quantitative description of the observations while simultaneously adhering to a given scientific hypothesis about how the data are generated.
Despite the growing ability of deep learning and other advanced machine learning techniques to extract useful information from complex data sets, mechanistic models continue to be important in modern science since mechanistic models are superior to machine learning models for interpretability of parameters \citep{baker18,hogg24}.
The ability of mechanistic models to describe scientifically important yet unobservable system states \citep{andrade22} also facilitates predictions of the impact of interventions on the system, such as masking or vaccination efforts during a disease outbreak \citep{wheeler24}.  

Contemporary applications of nonlinear mechanistic models for low-dimensional systems are abundant \citep[e.g.,][]{kramer24,he24,newman23}, yet examples of higher-dimensional panel equivalents remain sparse.
In principle, that could be explained by a lack of panel data, or by scientists being uninterested in applying mechanistic models to panel data.
Alternatively, the lack of examples may be indicative that scientists have struggled, largely unsuccessfully, to use existing statistical methodology.
Our work addresses this possibility by proposing a new algorithm that is effective on benchmark problems, theoretically supported, and easy to implement using existing software such as the R package \texttt{panelPomp} \citep{panelpomp}.

Various previously proposed algorithms, both frequentist and Bayesian, are capable in principle of fitting mechanistic models to panel data.
Some algorithms scale well as the model's dimension grows, but they rely on unrealistic Gaussian approximations \citep{evensen09}, or they avoid the difficulties related to evaluating the model's likelihood function by optimizing alternative measures of goodness-of-fit \citep{toni09,wood10}.
Other algorithms can be applied in less restrictive cases, but they scale poorly as the model's dimension increases \citep{andrieu10,ionides15}.

An extensively used approach in ecology, known as \emph{data cloning} \citep{lele07,lele10}, involves iteratively using Bayes' rule, by recursively mapping a prior distribution to a posterior distribution using the same likelihood function, until the iterated posterior distribution converges to a point mass at the maximum likelihood estimate (MLE).
Data cloning is equivalent to performing a Bayesian update on multiple copies of the data when the data are independent and identically distributed.
\citet{ionides15} developed an extension of data cloning for nonlinear non-Gaussian state space models by treating the model parameters as latent states, and performing a random walk for these parameters at each observation time.
By iteratively applying a particle filter \citep{arulampalam02} to this extended model and decreasing the random walk standard deviations over time, it can be shown that the parameters will converge to the MLE after a sufficiently large number of iterations \citep{ionides15, chen24}.
This algorithm, known as IF2, has seen extensive use for inference on low dimensional dynamic models, especially in epidemiological contexts \citep[e.g.,][]{pons-salort18,stocks20,subramanian21,fox22}.

In panel models, the iterated filtering algorithm must be extended to handle the Monte Carlo error that grows exponentially with the number of units.
To address this, \citet{breto20} proposed an algorithm called the panel iterated filter (PIF).
As discussed in Appendix~\ref{sec:panelTheory}, this algorithm is a special case of iterated filtering where the model structure and random walk sequence have been modified to reduce the loss of information that is described by \citet{liuwest01}.
The PIF algorithm has been effective in obtaining maximum likelihood estimates for highly non-linear, non-Gaussian panel models in previous works \citep{ranjeva17,ranjeva19,lee20,domeyer22}.
However, as we demonstrate here, the PIF algorithm can be inefficient when the number of units is large, due to the resampling of all parameters at each step of the iterated particle filters.

In order to improve the computational inefficiencies of the PIF algorithm for high-dimensional panel models, we present a novel inference technique which we call the marginalized panel iterated filter (MPIF).
This algorithm reduces the number of times particles are resampled using a marginalization process.
This improves computational efficiency by increasing the diversity of the particles that represent the parameter distribution at each iteration and time step.

The article proceeds by introducing PanelPOMP models, the mathematical framework we use to discuss mechanistic models for panel data. 
We then establish theoretical guarantees for the convergence of iterated filtering algorithms for these models (Theorem~\ref{theorem:pif}).
Our theoretical framework extends the analysis by \citet{chen24} to panel data while requiring weaker conditions than those by \citet{breto20}. 
We then introduce the marginalization step of MPIF that facilitates high dimensional inference by describing a concept we call marginalized Bayes maps.
The marginalization step introduces a nonlinearity in the Bayes map that existing theoretical approaches cannot immediately address.
We provide theoretical guarantees of the MPIF algorithm for some special cases, and demonstrate that the algorithm remains effective in a more general setting via a simulation study.
We then conduct a data analysis of a high-dimensional dataset of pre-vaccination measles case reports from 20 towns in the United Kingdom (UK).

\section{Iterated filtering for panel models}\label{sec:ppomp}

% To set up mathematical notation for PanelPOMP models, we first give a formal definition of a POMP.
% A POMP model comprises an unobserved Markov process $\mathbf{X}(t)$, where $t \in \mathcal{T}\subset \mathbb{R}$ and $\mathbf{X}(t)$ takes values in $\mathcal{X} \subset \mathbb{R}^{d_x}$.
% The process is initialized at time $t_0 \in \mathcal{T}$, such that $t_0\leq t'$ for all $t' \in \mathcal{T}$.
% Observations are drawn from the dynamic system at time points $t_1, \ldots, t_N \in \mathcal{T}$, and we denote the observation measured at time $t_n$ as $\mathbf{y}^*_n \in \mathcal{Y} \subset \mathbb{R}^{d_y}$.
% We assume that the observation $\mathbf{y}^*_n$ is a single realization of a random variable $\mathbf{Y}_n$.
% 
% While $\mathbf{X}(t)$ may be a continuous or discrete time process, the value of $\mathbf{X}(t)$ at observation times $t_{1:N}$ is often of particular interest, and so we write $\mathbf{X}_n = \mathbf{X}(t_n)$.
% This gives rise to a joint probability density or probability mass function $f_{\mathbf{X}_{0:N}, \mathbf{Y}_{1:N}}(\mathbf{x}_{0:N}, \mathbf{y}_{1:N}; \theta)$ at the observation times $t_{0:N}$.
% For the remainder of this article, we use the term {\it density} to refer to both probability densities and probability mass functions, the latter being formally treated as densities with respect to a counting measure on a finite or countable set.
% To complete the POMP specification, we assume that the observed random variables $\mathbf{Y}_{1:N}$ are conditionally independent given the values of the latent process $\mathbf{X}_{1:N}$.

In a panel data analysis scenario, data are collected for each unit in the panel.
Because the data generating process of each unit are assumed to be dynamically independent, we may model the panel data as a collection of related POMP models, which we call a PanelPOMP.
We denote the collection of measurements on the units $\unit \in \seq{1}{\Unit}$ as $Y_{u, n}$.
Often the observations occur at the same time for all units, in which case it is convenient to express the collection of POMP models as $\bm{X}(t) = \{X_u(t)\}_{u = 1}^U$ where $X_\unit(t)$ denotes the latent process for unit $\unit$ at time $t \in \mathcal{T}$.
The measurements at time $t_n \in \mathcal{T}$ are similarly written as $\bm{Y}_{n} = \{Y_{u, n}\}_{u = 1}^U$.
This notation also generalizes to the case where measurements are taken at distinct measurement times.
In this scenario, we let $N_u$ be the number of observations for unit $u \in \seq{1}{U}$, and each observation time is denoted as $t_{u, n} \in \mathcal{T}_u \subset \mathcal{T}$. 
We adopt the convention that if $t \notin \mathcal{T}_u$, $X_u(t) = 0_{d_x}$, and denote $X_{u}(t_{u, n}) = X_{u, n}$ for all measurement times $t_{u, n} \in \mathcal{T}_u$.
The joint density of the model can be written as
\begin{align}
f_{\mathbf{X}_{0:N}, \mathbf{Y}_{1:N}}(\mathbf{x}_{0:N}, \mathbf{y}_{1:N}; \theta) &= \prod_{u = 1}^U f_{X_{u, 0:N_u}, Y_{u,1:N_u}}(x_{u, 0:N_u}, y_{u, 1:N}; \theta) \label{eq:ppomp} \\
&\hspace{-2cm} = \prod_{u = 1}^Uf_{X_{u, 0}}(x_{u, 0};\theta)\prod_{n = 1}^{N_u}f_{Y_{u, n}|X_{u, n}}(y_{u, n} | x_{u, n} ;\theta)f_{X_{u, n} | X_{u, n-1}}(x_{u, n}|x_{u, n-1}; \theta), \label{eq:ppomp2}
\end{align}
where Eq.~\ref{eq:ppomp} arises from the assumption of dynamically independent units, and Eq.~\ref{eq:ppomp2} is a result of the Markov property of $X_{u}(t)$ and the conditional independence of $Y_{u, n}$.

Our goal is to make inferences about the parameter $\theta$ by maximizing the likelihood function (Eq.~\ref{eq:likedef}).
% \begin{align}
% \math(\theta;\mathbf{y}^*) &= \int f_{\mathbf{X}_{0:N}, \mathbf{Y}_{1:N}}(\mathbf{x}_{0:N}, \mathbf{y}^*_{1:N}; \theta)\, d\mathbf{x}_{0:N}. \label{eq:likelihood}
% \end{align}
Although the unit densities in Eq.~\ref{eq:ppomp} can be factored as a result of the dynamic independence between measurement units, a defining feature of a panel model is that the parameter vector $\theta$ remains relevant across all the dynamic systems.
Therefore, inference methodology used to obtain estimates of $\theta$ should use data from each unit in the PanelPOMP.
A special case of particular interest arises when $\theta = (\phi, \psi_{1:U})$, where $\phi \in \Theta_\phi \subset \mathbb{R}^{\nshared}$ is a vector of parameters that are shared across each unit, and $\psi_{u} \in \Theta_\psi \subset \mathbb{R}^{\nspecific}$ are parameters that are specific to unit $u$, formally,
$$
f_{X_{u, 0:N_u}, Y_{u,1:N_u}}(x_{u, 0:N_u}, y_{u, 1:N}; \, \theta) = f_{X_{u, 0:N_u}, Y_{u,1:N_u}}(x_{u, 0:N_u}, y_{u, 1:N}; \, \phi, \psi_u).
$$
Algorithm~\ref{alg:mpif} describes an iterated filtering algorithms for PanelPOMP models that obtains the MLE for both shared $(\phi)$ and unit specific $(\psi_u)$ parameters.
With $\mathrm{MARGINALIZE}=\mathrm{FALSE}$, this is the PIF algorithm of \citet{breto20}.
Our innovation occurs when $\mathrm{MARGINALIZE}=\mathrm{TRUE}$, and we call this the  marginalized panel iterated filter (MPIF).
MPIF can be decomposed into sub-steps that each resemble a single iteration of the IF2 algorithm.
However, MPIF adds an additional step to IF2 by marginalizing out the unit-specific parameters that are irrelevant for the unit currently being filtered.
Since the parameter distributions are represented via Monte Carlo samples, the marginalization step is implemented by not resampling the particles corresponding to the unit-specific parameters of other units.
In other words, instead of resampling all parameter particles in line~\ref{mpif:update} of Algorithm~\ref{alg:mpif}, we only resample particles for the shared parameters and the unit-specific parameters related to the data of the specific unit under consideration.

\begin{algorithm}[H]
   \caption[MPIF]{\textbf{Iterated Filtering for PanelPOMP models} \\
    {\bf Inputs}:\\\hspace{\textwidth}
    Simulator of initial density, $f_{X_{u, 0}}(x_{u, 0}; \theta)$ for $u$ in $\seq{1}{U}$.\\\hspace{\textwidth}
    Simulator of transition density, $f_{X_{u, n}|X_{u, n-1}}(x_{u, n}|x_{u, n-1}; \theta)$ for $u$ in $\seq{1}{U}$, $n$ in $\seq{1}{N_u}$.\\\hspace{\textwidth}
    Evaluator of measurement density, $f_{Y_{u, n}|X_{u, n}}(y_{u, n}|x_{u, n} ; \theta)$ for $u$ in $\seq{1}{U}$, $n$ in $\seq{1}{N_u}$.\\\hspace{\textwidth}
    Data $y_{u, n}^*$,for $u$ in $\seq{1}{U}$, $n$ in $\seq{1}{N_u}$.\\\hspace{\textwidth}
    Number of iterations, $M$.\\\hspace{\textwidth}
    Number of particles, $J$.\\\hspace{\textwidth}
    Starting parameter swarm, $\Theta_j^0 = \big(\Phi_j^0, \Psi_{1:U, j}^0\big)$ for $j \in \seq{1}{J}$, $u \in \seq{1}{U}$.\\\hspace{\textwidth}
    Simulator of perturbation densities, $h_{u, n}(\cdot | \varphi; \sigma)$ for $m \in \seq{1}{M}$, $u \in \seq{1}{U}$, $n \in 0:N_u$. \\\hspace{\textwidth}
    Perturbation Sequence $\sigma_{1:U, 1:M}$.\\\hspace{\textwidth}
    Logical variable determining marginalization, MARGINALIZE. \\\hspace{\textwidth}
    {\bf Output:} \\\hspace{\textwidth}
    Final parameter swarm, $\Theta_{j}^{m} = \big(\Phi_j^m, \Psi_{\seq{1}{U}, j}^m\big)$ for $j \in \seq{1}{J}$, $u \in \seq{1}{U}$.
    \label{alg:mpif}}
\For{$m \in 1:M$}{
  Set $\Theta_{0, j}^{F, m} = \Theta_{j}^{m-1} = (\Phi_j^{m-1}, \Psi_{1:U, j}^{m-1})$ for $j \in \seq{1}{J}$\;
    \For{$u \in \seq{1}{U}$}{
        Set $\Theta_{u, 0, j}^{F, m} = (\Phi_{u, 0, j}^{F, m}, \Psi_{1:U, 0, j}^{F, m}) \sim h_{u, 0}\big(\cdot | \Theta^{F, m}_{u-1, j}; \sigma_{u, m}\big)$ \label{line:startu}\; 
      Initialize $X_{u, 0, j}^{F, m} \sim f_{X_{u, 0}}(x_{u, 0}; \Phi_{u, 0, j}^{F, m}, \Psi_{u, 0, j}^{F, m})$ for $j \in \seq{1}{J}$\;
        \For{$n \in \seq{1}{N_u}$} {
          Set $\Theta_{u, n, j}^{P, m} = (\Phi_{u, n, j}^{P, m}, \Psi^{P, m}_{1:U, n, j}) \sim h_{u, n}\big(\cdot |\Theta_{u, n-1, j}^{F, m}; \sigma_{u, m}\big)$ for $j \in \seq{1}{J}$ \label{line:perturbations}\;
          $X_{u, n, j}^{P, m} \sim f_{X_{u, n}|X_{u, n-1}}\big(x_{u, n}|X_{u, n-1, j}^{F, m}; \Phi_{u, n, j}^{P, m}, \Psi_{u, n, j}^{P, m}\big)$ for $j \in \seq{1}{J}$ \label{line:Xpred}\;
          $w_{u, n, j}^m = f_{Y_{u, n}|X_{u, n}}\big(y_{u, n}^*|X_{u, n, j}^{P, m};\Phi_{u, n, j}^{P, m}, \Psi_{u, n, j}^{P, m}\big)$ for $j \in \seq{1}{J}$ \label{line:weights}\;
          Draw $k_{\seq{1}{j}}$ with $P(k_j = i) = w_{u, n, i}^m / \sum_{v = 1}^J w_{u, n, v}^m$ for $i, j \in \seq{1}{J}$\;
          Set $X_{u, n, j}^{F, m} = X_{u, n, k_j}^{P, m}$, and $\big(\Phi_{u, n, j}^{F, m}, \Psi_{u, n, j}^{F, m}\big) = \big(\Phi_{u, n, k_j}^{P, m}, \Psi_{u, n, k_j}^{P, m}\big)$ for $j \in \seq{1}{J}$\;
            \uIf{$\mathrm{MARGINALIZE}$}{$\Psi^{F,m}_{\tilde u,n,j} = \Psi^{P,m}_{\tilde u,n,j}$ for all $\tilde u \neq u$, $j=\seq{1}{J}$\label{mpif:update}} 
       \Else{$\Psi^{F,m}_{\tilde u,n,j} = \Psi^{P,m}_{\tilde u,n,k_j}$ for all $\tilde u \neq u$, $j=\seq{1}{J}$}
        }
      Set $\Theta_{u, j}^{F, m} = \big(\Phi_{u, N_u, j}^{F, m}, \Psi_{u, N_{1:U}, j}^{F, m}\big)$ for $j \in \seq{1}{J}$ \label{line:endu}\;
    }
  Set $\Theta_j^{(m)} = \Theta_{U, j}^{F, m}$ for $j \in \seq{1}{J}$\;
}
\end{algorithm}

The algorithmic complexity of both PIF and MPIF is $O(JMNU)$, where $M$ represents the number of iterations, $J$ is the number of particles, $U$ the number of units in the panel, and $N$ is the mean of $\{N_1, \ldots, N_U\}$.
However, because MPIF does not require tracking the history of each particle, we achieve a minor reduction in computational overhead associated with the PIF algorithm.
This reduction translates to faster iteration speeds and lower memory requirements, but, more importantly, MPIF can converge more quickly and exhibit reduced Monte Carlo uncertainty.

Central to the success of iterated filtering algorithms (and other data cloning algorithms) is the fact that iterative use of the posterior distribution from a Bayesian parameter update as the prior in subsequent iterations leads to a degenerate distribution centered at the MLE.
This idea is key to deriving the proof of Theorem~\ref{theorem:pif}, which provides theoretical guarantees for special cases of Algorithm~\ref{alg:mpif}.

\begin{theorem}\label{theorem:pif}
  Consider a PanelPOMP model defined by Eq.~\ref{eq:ppomp}, and let $\Theta \subset \R^{\nshared + \Unit\nspecific}$ be a compact set that satisfies condition \ref{assumption:regular}.
  Assume the conditions of Appendix~\ref{sec:assumptions} are satisfied and that there exists a $\delta > 0$ such that $\{\theta \in \Theta: |\theta - \hat{\theta}|_2 < \delta\} \subseteq \Theta$, where \linebreak $\hat{\theta} = \argmax_{\theta \in \Theta} L(\theta;\bm{y}^*)$.
  Denote the output of Algorithm~\ref{alg:mpif} without marginalization as $\Theta_{1:J}^{(M)}$.
  Then there exists some positive sequences $\{C_M\}_{M \geq 1}$ and $\{\epsilon_M\}_{M \geq 1}$ where $\lim_{M \rightarrow \infty}\epsilon_M = 0$ such that for all $(J, M) \in \mathbb{N}^2$,
  $$
  E\bigg[\Big|\frac{1}{J}\sum_{i=1}^J \Theta_j^{(M)} - \hat{\theta}\Big|_2\bigg] \leq \frac{C_M}{\sqrt{J}} + \epsilon_M
  $$
\end{theorem}
\begin{proof}[Proof outline]
  This theorem is an extension of Theorem~4 of \citet{chen24} to PanelPOMP models, following the approach of \citet{breto20}, who showed that PanelPOMP models can be expressed as a lower-dimensional POMP model. 
  Using this technique, the lower-dimensional version of the model has a corresponding self-organized state space model that has a filtering distribution with mass centered at $\hat{\theta}$, and Algorithm~\ref{alg:mpif} is a particle filter applied to the self-organized state space model. A full proof is provided in Appendix~\ref{sec:panelTheory}.
\end{proof}

Theoretic guarantees for the PIF algorithm have previously been studied by \citet{breto20}.
Here we use a similar approach to extend the analytic framework of \citet{chen24} in order to obtain stronger convergence guarantees for PIF under weaker assumptions than \citet{breto20}.
Theorem~\ref{theorem:pif} formally provides guarantees for a variety of iterated filtering algorithms for PanelPOMP models, but as we demonstrate here, the applicability of these algorithms often have scalability issues.
The marginalization step in Algorithm~\ref{alg:mpif} mitigates these issues, but introduces a nonlinearity that invalidates the data cloning principle that is key to previous theoretical work on iterated filtering algorithms. 
In the following section, we briefly discuss data cloning and its relationship to the MPIF algorithm.

\section{Iterating marginalized Bayes maps}

If we denote $\pi_i(\theta)$ as the posterior distribution of the parameter vector $\theta$ after the $i$th Bayesian update, and $\bm{y}^* = \bm{y}_{1:N}^*$ as the observed data, we can express an iterated Bayesian update as the following:
\begin{align*}
\pi_1(\theta) &\propto f(\bm{y}^* ;\, \theta)\pi_0(\theta), \\
\pi_2(\theta) &\propto f(\bm{y}^* ;\, \theta)\pi_1(\theta) \propto f^2(\bm{y}^* ;\, \theta)\pi_0(\theta),\\
&\vdots \\
\pi_m(\theta) &\propto f^m(\bm{y}^* ;\, \theta)\pi_0(\theta).
\end{align*}
In this representation, $f(\bm{y}^*; \,\theta)$ is the likelihood function (Eq.~\ref{eq:likedef}), and $\pi_0(\theta)$ is the original prior distribution for $\theta$.
If we let $m\rightarrow \infty$, the effect of the initial prior distribution diminishes, and the $m$th posterior has all of its mass centered at the MLE.
This can be shown by taking the limit of $\pi_m(\theta) / \pi_m(\hat{\theta})$ as $m$ goes to infinity: if $\theta = \hat{\theta}$, then the limit is one, and zero otherwise \citep{lele07}.

This data cloning algorithm is useful for estimating the MLE in situations where the likelihood function is known or readily evaluated up to a constant of proportionality.
In this scenario, practitioners can leverage existing Bayesian software in order to obtain a maximum likelihood estimate (MLE) \citep{auger21,ponciano09}.
However, for non-linear non-Gaussian state-space models, the likelihood function is generally inaccessible.
In these cases, simulation-based inference techniques such as the particle filter \citep{arulampalam02} can reliably approximate the likelihood function.
An iterated Bayes procedure could in theory be used in conjunction with a particle filter to estimate the MLE.
However, a well-known issue with particle filters is the difficulty in accurately sampling the posterior distribution of fixed model parameters due to particle depletion \citep{liuwest01}.
Consequently, a direct application of the iterated Bayes approach using particle filters for MLE estimation is impractical.

Iterated filtering algorithms overcome the issues associated with particle depletion by introducing a random walk for model parameters, thereby rescuing the degenerate particle representation of model parameters.
Early analysis of this procedure showed that if the random walk standard deviations are small, then this modification still leads to an approximation of the iterated Bayes algorithm outlined above, where the final particle mass is still centered at the MLE \citep{ionides15}.
The introduced perturbations of parameter values are necessary for inference, but they also introduce a loss of information \citep{liuwest01}.
Therefore, in practice, the random perturbations are reduced as the number of iterations increases; recent theoretical analysis also demonstrates that the algorithm still concentrates on the MLE when perturbations are reduced over time \citep{chen24}.

Because PanelPOMP models are a special case of POMP models, this same approach can theoretically be used to estimate the MLE.
However, the particle filter famously suffers from the curse-of-dimensionality.
That is, the approximation error of the particle filter grows exponentially with the number of units in a panel model \citep{bengtsson08,snyder08}.
The panel iterated filter (PIF) of \citet{breto20} partially addresses this issue by stacking the individual time series into a single long time series, and modifying the perturbation kernel for parameter particles to mitigate loss of information, as discussed in Section~\ref{sec:mpifdiscussion}.
Importantly, the PIF algorithm still approximates the iterated Bayes map when the random walk standard deviations are small (Theorem~1 of \citet{breto20}), and can be shown to converge when the perturbations shrink over time (our Theorem~\ref{theorem:pif}).

The additional marginalization step in the MPIF algorithm introduces a nonlinear transformation at each iteration, changing the distribution that is approximated by the algorithm. 
As such, existing theoretic approaches for iterated filtering algorithms \citep{chen24} for this class of models are insufficient to demonstrate convergence of the algorithm. 
We explore why this is the case in the context of \emph{marginalized data cloning}. 
Let $\theta = (\phi, \psi_{1:U})$ denote the parameter vector for the panel model, where $\phi$ denotes the parameters that are shared by all $U$ units, and $\psi_u$ are the parameters that are only relevant to unit $u$.
Similarly, we write $y_u^* = y^*_{u, 1:N_u}$ to denote the time series data for unit $u$.
By stacking the times series into a single timeseries and iteratively filtering one at a time and ignoring parameter perturbations, the Bayes map that is approximated by a single sub-iteration of PIF can be written sequentially as:
\begin{align}
\pi_{m, u}(\theta) &\propto f_{u}(y^*_u;\, \theta)\, \pi_{m, u-1}(\theta) = f_{u}(y^*_u;\, \phi, \psi_u)\, \pi_{m, u-1}(\theta), \label{eq:PIFupdate}
\end{align}
where $\pi_{m, u}(\theta)$ is the parameter distribution at step $(m, u)$, and we adopt the convention that $\pi_{0, 0}(\theta) = \pi_0(\theta)$ is the initial prior density and $\pi_{m, U} = \pi_{m + 1, 0} = \pi_{m + 1}$.
This update is completed for each unit $u \in \seq{1}{U}$ which we call unit-iterations, then for iterated for $m \in \seq{1}{M}$, which we call complete or full iterations.

An important observation regarding the representation in Eq.~\ref{eq:PIFupdate} is that each unit-specific likelihood function $f_{u}(y^*_u;\, \phi, \psi_u)$ contributes directly to the information about the shared parameter vector $\phi$ and its respective unit-specific parameter vector $\psi_u$, but not that of the unit-specific parameters $\{\psi_{k}\}_{k \neq u}$.
Despite this, the Bayes update in the PIF algorithm necessitates updating the posterior distribution of all parameters at each unit-iteration.
Because the parameter distributions are represented via Monte Carlo samples (called particles), this implies that the PIF algorithm re-weights particles based on a likelihood that is not directly connected to certain parameters.
For example, within a single $\nmif$-iteration, the particles representing the distribution of $\psi_U$ have been resampled $\sum_{\unit = 1}^{U - 1}N_u$ times before encountering the data $y^*_U$, the only subset of data containing direct information about $\psi_U$.
This process can lead to significant particle depletion, particularly if $U$ or $N_u$ are large (see Figure~\ref{fig:depletion}).

If the prior distribution used in Eq.~\ref{eq:PIFupdate} is marginally independent, then the posterior distribution of $\{\psi_{k}\}_{k \neq u}$ will be unchanged.
In this case, the particles representing the density for these parameters do not need to be resampled, which would avoid the issue of particle depletion.
The use of independent priors is common practice in Bayesian statistics, but each full-iteration of Eq.~\ref{eq:PIFupdate} introduces parameter dependence via the likelihood function.
This observation leads to the proposal of the marginalized PIF algorithm (MPIF), where the intermediate posterior distributions are made independent before use as a prior distribution in the subsequent unit-iteration. 
A representation of a unit-iteration following this approach is given in Eqs.~\ref{eq:margBayes} and~\ref{eq:MPIFupdate}.
\begin{align}
\tilde{\pi}_{m, u}(\theta) &\propto f_{u}(y^*_u;\, \phi, \psi_u)\, \pi_{m, u-1}(\theta) \label{eq:margBayes}\\
\pi_{m, u}(\theta) &\propto \int \! \tilde{\pi}_{m, u}(\theta) \, d\phi \, d\psi_u \, \times \int \! \tilde{\pi}_{m, u}(\theta) \, d\psi_{-u} \label{eq:MPIFupdate}.
\end{align}

Here we have described iterated filtering algorithms while ignoring parameter perturbations and Monte Carlo evaluations of the likelihood function. 
Each of these components play an important role in the practicality of iterated filtering, but existing theoretical justifications rely on the convergence of data cloning to the MLE, and show that the convergence still holds in spite of the additional complexities.
A natural question is whether iterating Eqs.~\ref{eq:margBayes}--\ref{eq:MPIFupdate} results in a probability distribution with all mass centered at the MLE(s), similar to the case without marginalization. 
The non-linearization introduced by the marginalization, however, adds difficulty to the task of calculating, or bounding, the density.
In particular, previous approaches that rely on the linearization of unnormalized Bayes updates \citep[e.g.,][]{ionides15} are no longer applicable.
In the following subsection, we show that iterating Eq.~\ref{eq:MPIFupdate} does converge to the MLE when the likelihood is Gaussian.

\subsection{Consistency for Gaussian models}

For Gaussian models, conditioning and marginalization can be carried out exactly.
The properties of this analytically tractable special case is relevant to the broader class of models that is well approximated by Gaussian models, for example, models satisfying the widely studied property of local asymptotic normality (LAN) \citep{lecam00}.
We show in Theorem~\ref{theorem:GG} that MPIF for a Gaussian model converges to the exact MLE as long as unit-specific parameters are not highly informative about shared parameters.

As before, we assume there are $U \geq 1$ units, and the likelihood of each unit is defined by $L_u(\theta) = f_u(y_u^*; \, \phi, \psi_u)$, and the likelihood of the entire model is $L(\theta) = \prod_{u = 1}^U L_{u}(\phi, \psi_u)$.
In what follows, we assume $\phi \in \R$ and $\psi_u \in \R$ for all $u \in \seq{1}{U}$ in order to ease the notation and analysis.

\begin{theorem}
  Let $f_u(y_u^*; \, \phi, \psi_u)$ be the density that corresponds to a Gaussian distribution with mean $(\phi^*, \psi_u^*)$ and precision $\Lambda_u^* \in \R^{2\times2}$. 
Assume that $\Lambda^*_u$ satisfies
\begin{align}
\big[\Lambda^*_{u}\big]_{1, 2}^2 <
  \frac{
    4 \big[\Lambda^*_{u}\big]_{1, 1}\, \big[\Lambda^*_{u}\big]^2_{2, 2}
    \, \sum_{k=1}^U \big[\Lambda^*_{k}\big]_{1, 1}
  }{
    \Big( \big[\Lambda^*_{u}\big]_{2, 2} + \sum_{k=1}^U\big[\Lambda^*_{k}\big]_{1, 1}\Big)^2
  }. \label{eq:GausAssumption}
\end{align}
  If the initial prior density $\pi_0(\theta) = \pi_{0, 0}(\theta)$ corresponds to a Gaussian distribution with mean $\mu_0$ and covariance $\Sigma_0$, then the density of the $m$th iteration of Eq.~\ref{eq:MPIFupdate} corresponds to a Gaussian distribution with mean $\mu_m \in \R^{U+1}$ and covariance $\Sigma_{m} \in \R^{U+1\times U+1}$ such that $\mu_m \rightarrow (\phi^*, \psi_1^*, \ldots, \psi_U^*)$ and $\|\Sigma_m\|_{2} \rightarrow 0$. That is, the algorithm converges to a point mass at the MLE. \label{theorem:GG}
\end{theorem}

The proof of Theorem~\ref{theorem:GG} is included in Appendix~\ref{appendix:Gaus}.
At each iteration of the algorithm, the marginalization step results in a loss of information about the likelihood surface. 
In the Gaussian setting, this equates to setting the covariance term between the shared and unit-specific parameters to be zero before performing a Bayes update. 
The assumption in Eq.~(\ref{eq:GausAssumption}) therefore helps mitigate this loss of information by controlling the size of the covariance in the likelihood surface. 
If the data are transformed to ensure that the likelihood covariance matrix has ones on the diagonal, that is, 
$
\Sigma^*_u = (\Lambda_u^*)^{(-1)} = \begin{pmatrix} 1 & \rho \\ \rho & 1\end{pmatrix}, 
$
then $\big[\Lambda^*_{u}\big]_{1, 1} = \big[\Lambda^*_{u}\big]_{2, 2} = 1 / (1-\rho^2)$ and $\big[\Lambda^*_{u}\big]_{1, 2} = \big[\Lambda^*_{u}\big]_{2, 1} = -\rho/(1-\rho^2)$.
In this case, the convergence condition in Eq.~(\ref{eq:GausAssumption}) becomes
$$
\rho < \frac{2}{\sqrt{U}\big(1 + 1/U\big)}. 
$$

The proof of Theorem~\ref{theorem:GG} shows that the condition in Eq.~(\ref{eq:GausAssumption}) is sufficient for a convergence guarantee, but it may not be necessary. 
Furthermore, even some asymptotic bias may be tolerable compared to alternative algorithms that fail to scale. 
As demonstrated in Section~\ref{sec:depletion}, the particle depletion suffered by PIF can result in MPIF obtaining a better approximation of the unmarginalized map than the PIF algorithm.
In this case, MPIF is preferable to PIF even if the marginalized map results in a small bias.

Theorem~\ref{theorem:GG} provides convergence results for the algorithm in the absence of parameter perturbations. 
Using a similar setup, we can now consider the behavior of the algorithm with perturbations added to model parameters at each step. 
Let $f * g$ denote the convolution of probability densities $f$ and $g$. 
We assume that $h_{u, m}(\theta)$ is some perturbation density, and we modify the marginalized Bayes maps by adding this random noise at each unit-iteration.
\begin{align}
\tilde{\pi}'_{m, u}(\theta) &\propto f_{u}(y^*_u;\, \phi, \psi_u)\, \big(\pi'_{m, u-1} * h_{u, m}\big)(\theta) \label{eq:margBayesPerturb}\\
\pi'_{m, u}(\theta) &\propto \int \! \tilde{\pi}'_{m, u}(\theta) \, d\phi \, d\psi_u \, \times \int \! \tilde{\pi}'_{m, u}(\theta) \, d\psi_{-u} \label{eq:MPIFupdatePerturb},
\end{align}
Corollary~\ref{corollary:perturbed} shows that, under similar conditions as Theorem~\ref{theorem:GG}, marginalized data cloning with perturbations also converges to a point mass at the MLE if the likelihood is Gaussian.

\begin{corollary}\label{corollary:perturbed}
  Consider the setup of Theorem~\ref{theorem:GG}. If the parameter perturbations are Gaussian with covariance matrix $\sigma^2_m \Sigma_0$ for some initial covariance matrix $\Sigma_0 \in \R^{(U+1) \times (U+1)}$ and sequence $\sigma^2_m = o(1/m)$, then the $m$th iteration of Eqs.~\ref{eq:margBayesPerturb} and \ref{eq:MPIFupdatePerturb} corresponds to a Gaussian distribution with mean $\mu'_m \in \R^{U+1}$ and covariance $\Sigma'_m \in \R^{U+1\times U+1}$. If $\hat{\theta} = (\phi^*, \psi^*_1, \ldots, \psi^*_{U})$ denotes the MLE, then $|\mu'_m - \hat{\theta}|_2 \rightarrow 0$ and $\|\Sigma'_m\|_2 \rightarrow 0$.
\end{corollary}

The convergence of the Eqs.~\ref{eq:margBayesPerturb}--\ref{eq:MPIFupdatePerturb} can be partially explained using a common heuristic in Bayesian analysis: a more dispersed prior typically results in a posterior distribution that more closely resembles the likelihood function. 
In an iterated Gaussian setting, adding noise at each step results in intermediate prior distributions that have the same mean, but larger variance.
Therefore each iteration of Eq.~\ref{eq:margBayesPerturb} is expected to result in a mean closer to the MLE than the case without perturbations (Eq.~\ref{eq:margBayes}). 
Following this logic, if the perturbations are chosen to ensure that they eventually approach zero, then the convergence of the unperturbed marginalized data cloning algorithm heuristically implies the convergence of the perturbed version of the algorithm. 
The proof of Corollary~\ref{corollary:perturbed} in Appendix~\ref{appendix:perturbed} demonstrates that this is true for the Gaussian model and the chosen perturbation schedule. 

In principle, the marginalization procedure can be applied at various steps in the data cloning process and one can obtain similar convergence results. 
In Figure~\ref{fig:DC}, we demonstrate the difference between data cloning and marginalized data cloning for a two parameter model with Gaussian likelihoods and priors with only a single unit but applying the marginalization for all parameters.
This useful visualization demonstrates how, even when the likelihoods can be computed exactly, the marginalization only makes small modifications to the intermediate distributions.

\begin{figure}[ht]
<<figDC, fig.height=3.25, fig.width=5>>=
Lambda <- rbind(
  c(0.8, 0.45),
  c(0.45, 1.1)
)

Prior <- list(
  'mean' = c(11, 8),
  'precision' = diag(c(1, 1))
)

all_DC_dists <- GG_DC(
  Lambda = Lambda,
  Prior = Prior,
  M = 100
)

all_MDC_dists <- GG_MDC(
  Lambda = Lambda,
  Prior = Prior,
  M = 100
)

M <- 5
K <- ncol(Lambda) - 1

df_mu_DC <- data.frame(
  'mu1' = rep(NA_real_, (M + 1) * K),
  'mu2' = rep(NA_real_, (M + 1) * K),
  'step' = rep(0:M, each = K),
  'group' = "DC"
)
df_Sigma_DC <- data.frame(
  'X1' = rep(NA_real_, (M + 1) * 101 * K),
  'X2' = rep(NA_real_, (M + 1) * 101 * K),
  'group' = 'DC',
  'step' = rep(NA_integer_, (M + 1) * 101 * K)
)


df_mu_MDC <- data.frame(
  'mu1' = rep(NA_real_, (M + 1) * K),
  'mu2' = rep(NA_real_, (M + 1) * K),
  'step' = rep(0:M, each = K),
  'group' = "MDC"
)
df_Sigma_MDC <- data.frame(
  'X1' = rep(NA_real_, (M + 1) * 101 * K),
  'X2' = rep(NA_real_, (M + 1) * 101 * K),
  'group' = "MDC",
  'step' = rep(NA_integer_, (M + 1) * 101 * K)
)

# for (j in 1:M) {
for (j in 0:M) {
  start_row <- (K * (j)) + 1
  start_sigma <- ((j) * 101 * K) + 1

  tmp_transition <- t(all_DC_dists[[j + 1]]$mean)
  df_mu_DC[start_row:(start_row + K - 1), c('mu1', 'mu2')] <- tmp_transition
  Sigma_j <- list(
    solve(all_DC_dists[[j + 1]]$precision)
  )
  df_Sigma_DC[start_sigma:(start_sigma + (101 * K) - 1),
              c('X1', "X2", "group")] <- calculate_ellipse(tmp_transition, Sigma_j)
  df_Sigma_DC[start_sigma:(start_sigma + (101 * K) - 1),
              'step'] <- as.integer(j)


  tmp_transition <- t(all_MDC_dists[[j + 1]]$mean)
  df_mu_MDC[start_row:(start_row + K - 1), c('mu1', 'mu2')] <- tmp_transition
  Sigma_j <- list(
    solve(all_MDC_dists[[j + 1]]$precision)
  )
  df_Sigma_MDC[start_sigma:(start_sigma + (101 * K) - 1),
              c('X1', "X2", "group")] <- calculate_ellipse(tmp_transition, Sigma_j)
  df_Sigma_MDC[start_sigma:(start_sigma + (101 * K) - 1),
              'step'] <- as.integer(j)
}

df_mu_DC$group <- 'DC'
df_mu_MDC$group <- 'MDC'
df_Sigma_DC$group <- 'DC'
df_Sigma_MDC$group <- 'MDC'

like_elipse <- calculate_ellipse(
  matrix(c(0, 0), nrow = 1),
  list(solve(Lambda))
) |>
  dplyr::select(-group)

df_all_mu <- dplyr::bind_rows(
  df_mu_DC, df_mu_MDC
)

df_all_Sigma <- dplyr::bind_rows(
  df_Sigma_DC, df_Sigma_MDC
)

method_names <- c(
  DC = 'Data Cloning',
  MDC = 'Marginalized Data Cloning'
)

ggplot(df_all_mu) +
  geom_point(
    aes(x = mu1, y = mu2, col = as.factor(step)),
    pch = 18, size = 1
  ) +
  geom_path(
    data = df_all_Sigma,
    aes(x = X1, y = X2, col = as.factor(step))
  ) +
  geom_path(
    data = like_elipse,
    aes(x = X1, y = X2), linetype = 'dashed'
  ) +
  geom_point(x = 0, y = 0, col = 'red', pch = 'x') +
  theme_bw() +
  scale_x_continuous(limits = c(-3.12, 13.5)) +
  scale_y_continuous(limits = c(-3.12, 13.5)) +
  theme(aspect.ratio = 1) +
  labs(color = 'Step') +
  scale_color_manual(
    values = c(
      "#800026",
      "#bd0026",
      "#e31a1c",
      "#fc4e2a",
      "#fd8d3c",
      "#feb24c"
    )
  ) +
  labs(x = TeX('$\\phi$'), y = TeX('$\\psi$')) +
  theme(legend.position = 'right') +
  facet_wrap(~group, labeller = labeller(group = method_names)) + 
  theme(plot.margin = unit(c(0, 0, 0, 0), 'cm'))
@
\caption[Data cloning compared to marginalized data cloning for Gaussian densities.]{\label{fig:DC}Data cloning compared to marginalized data cloning for Gaussian densities. The ellipses show the region of the parameter distribution that contains $95\%$ of the probability mass of the distribution. The black dashed line shows this region for the likelihood surface, and the red ``x" marks the MLE.}
\end{figure}

\section{Simulation Studies}

\subsection{Marginalization to reduce particle depletion}\label{sec:depletion}

The primary benefit and motivation of the marginalization step is improving the particle representations of the intermediate parameter distributions. 
In this sense, the marginalization step can be viewed as an attempt to take advantage of a bias-variance tradeoff. 
The marginalization procedure introduces a small amount of bias in the Bayesian posterior at each step in order to greatly reduce the variance of the particle representations of the distribution.

We demonstrate this idea via a simple simulation study that explores the particle representation of parameter distributions with and without marginalization for only a single unit-iteration within Algorithm~\ref{alg:mpif}. 
For our model, we suppose $Y_{u, n}$ are independent and identically distributed ($\iid$) from a normal $\normal[\psi_u, 1]$ distribution, and do not specify a latent process model as it is irrelevant for this model.
We consider only $U = 2$ units, and $N_u = N = 100$ for all $u$.
For our prior distribution, we let $\Theta_{1:J}^{(0)} \overset{\iid}{\sim} \normal \big[ \mu_0, \, \Sigma_0 \big]$, and use $J = 1000$ particles to represent the joint parameter density.
This simple model and setup is selected so that the priors and likelihoods can be exactly calculated;
we can compare this to their particle representations using both versions of a single $u = 1$ iteration of Algorithm~\ref{alg:mpif} (Lines~\ref{line:startu}--\ref{line:endu}).

When iterating through unit $u = 1$, the Bayes map that is approximated by the un-marginalized filter requires an update to the particles that correspond to all model parameters for each time step $n \in \seq{1}{N_1}$. 
This reduces the number of unique particles that represent the intermediate posterior distributions for parameter $\Psi_2$ (Figure~\ref{fig:depletion}A). 
The number of unique particles representing $\Psi_1$ remains high as a result of the added parameter perturbations (line~\ref{line:perturbations}).
On the other hand, the MPIF algorithm does not require resampling the $\Psi_2$ particles during the $u = 1$ iteration, and thus maintains the same number of unique particles during this update (dashed horizontal line in Figure~\ref{fig:depletion}A).

Figure~\ref{fig:depletion}B shows the filtered parameter particle swarm $\Theta_{1, 1:J}^{F, 1}$ after the single unit update under both versions of the algorithm compared to the Bayes posterior distribution that PIF approximates.
Although the marginalized version of the algorithm does not directly approximate this distribution, the particle swarm suffers less from particle depletion. 
This results in a better approximation of the intermediate posterior, despite introducing a small amount of bias.
Theorem~\ref{theorem:GG} provides sufficient conditions where the added bias at each step is negligible enough for the algorithm to converge to the MLE.

\begin{figure}[ht]
<<fig.height=4.5, fig.width=5>>=
set.seed(54321)
N <- 100  # Number of observations  
J <- 1000  # Number of particles

like_mean <- 0  # Mean of the likelihood function
like_var <- 1  # Variance of the likelihood function
prior_mean <- c(2, 2)  # mean of the prior distribution
prior_cov <- rbind(c(2, 0.5), c(0.5, 1))  # Covariance matrix of the prior

Likelihood_Yi <- function(y_i, theta) {
  dnorm(y_i, mean = theta)
}

# Simulate Data from likelihood model
data_y <- rnorm(N, mean = like_mean, sd = sqrt(like_var))

# Get particle representation of prior
prior <- MASS::mvrnorm(
  J,
  mu = prior_mean, 
  Sigma = prior_cov
)

# Marginals.
prior1 <- prior[, 1]
prior2 <- prior[, 2]

# Keep track of how particle marginals change over time
all_priors1 <- matrix(nrow = N + 1, ncol = J)
all_priors2 <- matrix(nrow = N + 1, ncol = J)

all_priors1[1, ] <- prior1
all_priors2[1, ] <- prior2

# Update particle distribution, one observation at a time. 
for (i in 1:N) {
  
  prior1 <- rnorm(n = length(prior1), mean = prior1, sd = 0.02)  # small random noise
  weights <- Likelihood_Yi(data_y[i], theta = prior1)
  reg_weights <- weights / sum(weights)
  prior1 <- prior1[sample(1:length(prior1), length(prior1), prob = reg_weights, replace = TRUE)]
  prior2 <- prior2[sample(1:length(prior1), length(prior1), prob = reg_weights, replace = TRUE)]
  
  # Keep track of new particle distributions. 
  all_priors1[i+1, ] <- prior1
  all_priors2[i+1, ] <- prior2
}

# Convert to data.frame, for plotting. 
all_priors1_df <- as.data.frame(all_priors1) %>% 
  mutate(iteration = 0:N) %>% 
  pivot_longer(-iteration, names_to = 'sample', values_to = 'val') %>% 
  mutate(dist = '1')

all_priors2_df <- as.data.frame(all_priors2) %>% 
  mutate(iteration = 0:N) %>% 
  pivot_longer(-iteration, names_to = 'sample', values_to = 'val') %>% 
  mutate(dist = '2')

all_priors <- dplyr::bind_rows(all_priors1_df, all_priors2_df)

tmp <- all_priors %>% 
  group_by(dist, iteration) %>% 
  distinct(val) %>% ungroup()

compute_posterior <- function(y, sigma2, mu0, Sigma0) {
  # Ensure inputs are appropriate structures
  if (!is.vector(y) || !is.numeric(y)) stop("y must be a numeric vector")
  if (!is.matrix(Sigma0) || nrow(Sigma0) != 2 || ncol(Sigma0) != 2) stop("Sigma0 must be a 2x2 matrix")
  if (length(mu0) != 2) stop("mu0 must be a vector of length 2")
  
  # Calculate some needed constants
  N <- length(y)
  y_sum <- sum(y)
  
  # Compute the inverse of Sigma0
  Sigma0_inv <- solve(Sigma0)
  
  # Define the precision matrix of the likelihood part and prior part
  likelihood_precision <- diag(c(N / sigma2, 0))
  
  # Compute the posterior precision matrix
  posterior_precision <- likelihood_precision + Sigma0_inv
  
  # Compute the posterior covariance matrix (inverse of the precision matrix)
  Sigma_n <- solve(posterior_precision)
  
  # Compute the posterior mean
  b <- Sigma0_inv %*% mu0 + c(y_sum / sigma2, 0)
  mu_n <- Sigma_n %*% b
  
  # Return a list containing the posterior mean and covariance matrix
  list(mu_n = mu_n, Sigma_n = Sigma_n)
}

true_post <- compute_posterior(data_y, like_var, mu0 = prior_mean, Sigma0 = prior_cov)

post_df <- data.frame(
  dist = c('1', '2', '3'),
  mean = c(true_post$mu_n[1], true_post$mu_n[2], true_post$mu_n[2]),
  sd = c(sqrt(true_post$Sigma_n[1, 1]), sqrt(true_post$Sigma_n[2, 2]), sqrt(true_post$Sigma_n[2, 2]))
)

depParticlesPIF <- tmp %>% 
  group_by(dist, iteration) %>% 
  summarize(n = n_distinct(val)) %>% 
  mutate(dist = factor(dist, levels = c('1', '2'), labels = c(TeX('$\\Psi_1$'), TeX('$\\Psi_2$'))))

depParticlesMPIF <- depParticlesPIF %>% 
  mutate(
    n = case_when(dist == 'Psi[1]' ~ n, TRUE ~ max(n))
  )

depletion_1 <- depParticlesPIF %>% 
  ggplot(aes(x = iteration, y = n)) + 
  facet_wrap(
    ~dist, nrow = 1, labeller = label_parsed
  ) + 
  geom_line(col = MARG_COLS[2]) +
  geom_line(data = depParticlesMPIF, col = MARG_COLS[1], linetype = 'dashed') + 
  theme_bw() + 
  ylab("Number of\nUnique Particles") + 
  xlab(TeX("Observation Number $(n \\in 1 : N_1)$"))

final_prior <- data.frame(theta1 = prior1, theta2 = prior2)

posterior_ellipse <- calculate_ellipse(t(true_post$mu_n), list(true_post$Sigma_n))

final_prior$theta2_init <- all_priors2[1, ]

final_prior_long <- pivot_longer(
  data = final_prior, 
  cols = c("theta2", "theta2_init"),
  names_to = 'type',
  values_to = 'theta2'
)

depletion_2 <- ggplot() + 
  geom_point(data = final_prior_long, aes(x = theta1, y = theta2, col = type)) +
  geom_path(data = posterior_ellipse, aes(x = X1, y = X2), linetype = 'dashed', col = 'black', linewidth = 1) + 
  facet_wrap(~type, labeller = as_labeller(c(theta2 = "Unmarginalized", theta2_init = "Marginalized"))) + 
  theme_bw() + 
  ylab(TeX("$\\Psi_2$")) + 
  xlab(TeX("$\\Psi_1$")) + 
  theme(axis.title.y = element_text(margin = unit(c(0, 0.2, 0, 0.7), 'cm'))) + 
  scale_color_manual(values = rev(MARG_COLS)) + 
  theme(legend.position = 'none')

cowplot::plot_grid(depletion_1, depletion_2, nrow = 2, labels = "AUTO", rel_heights = c(0.425, 0.575))
@
\caption[Updating parameter distributions with a single $u = 1$ iteration of both versions of Algorithm~\ref{alg:mpif}.]{\label{fig:depletion}Updating parameter distributions with a single $u = 1$ iteration of both versions of Algorithm~\ref{alg:mpif}. (A) The total number of unique particles representing each parameter. The dashed horizontal line shows that MPIF maintains the number of particles for $\Psi_2$ over time. (B) Parameter particle swarm of a single update with and without marginalization compared to the true posterior distribution.}
\end{figure}

\subsection{Stochastic Gompertz Population Model}\label{sec:gompertz}

We demonstrate the efficacy of the MPIF algorithm by estimating the model parameters of a high-dimensional, nonlinear PanelPOMP model by fitting data simulated from a collection of stochastic Gompertz population models.
This model is commonly used to describe population dynamics in Ecology and has been used as a benchmark for comparison between various algorithms in previous studies \citep{breto20}.
The model assumes a latent state vector $X_{u, n}$ for each unit $u \in 1:U$ and $n \in 0:N$.
For each unit $u$, the latent state has a one-step transition density that satisfies
\begin{equation*}
X_{u,n+1} = K_u^{1-e^{r_u}} \, X_{u, n}^{e^{-r_u}}\, \epsilon_{u, n},
\end{equation*}
where $K_u$ is the carrying capacity for the population in unit $u$, $r_u$ is a positive parameter that corresponds to the growth rate, and $\epsilon_{u, n}$ are $\iid$ lognormal random variables such that $\log \epsilon_{u, n} \overset{\iid}{\sim} \normal[0, \sigma_u^2]$.

Measurements of the population are obtained via the density $\log Y_{u, n} \overset{\iid}{\sim} \normal \left[\log X_{u, n}, \, \tau_u^2\right]$
where $\tau_u$ is a positive variance parameter.
This model is a convenient non-linear non-Gaussian PanelPOMP model because a logarithmic transformation makes the model a linear Gaussian process, and as such the exact likelihood of the model can be calculated by the Kalman filter \citep{kalman60}.

For this simulation study, we generate data from several Gompertz population models, with equal number of observations $N$ in unit $u$, with values of $N \in \{20, 50, 100\}$ and values of $U$ ranging from $U=5$ to $U = 2500$.
To generate data from this model, we fix $K_u = 1$ and $X_{u, 0} = 1$ for all $u$ and treat these parameters as known constants.
We then set $\sigma_u^2 = 0.01$ and $r_u = 0.1$ for all values of $u$ to generate data, but treat these parameters as unknown shared parameters that need to be estimated from the data.
Finally, we set $\tau_u^2 = 0.01$ for all $u$ and treat these parameters as unknown unit-specific parameters.
These values were chosen to obtain comparable simulations and results as \citet{breto20}.

The models were fit using the MPIF algorithm with the number of iterations $M = 50$, and the number of particles $J = 1000$.
For this analysis, intermediate parameter estimates are obtained every five iterations of the MPIF algorithm, and the likelihood of the intermediate parameter values are obtained.
The goal of calculating the intermediate likelihood values is to demonstrate how many iterations are needed to obtain model convergence, and to compare the algorithms performance against that of the PIF algorithm for each time step.
Because the maximization procedure is inherently stochastic, it is recommended to try multiple starting parameter values.
Therefore for each model, 50 unique starting points are used; these starting points are randomly sampled from the hypercube with lower-bounds for each parameter determined by the generating parameter value divided by two, and the upper bound for the parameter defined as the generating parameter value multiplied by two.

The results of this simulation study with $N = 50$ are shown in Figure~\ref{fig:gomp}.
For every combination of $\{U, N\}$ considered, and for all numbers of MIF iterations, the maximum likelihood obtained using MPIF was higher than the maximum obtained using PIF. 
For large $U$, we also found that the worst performing Monte Carlo replicate of the MPIF algorithm often did better than the best performing replication of the PIF algorithm.
In the next section, we find similar results using a more complicated model to describe data that have previously been used as a means of comparing inference procedures.

<<loadGompertz, echo=FALSE>>=
results0 <- readRDS("data/GompertzRL3.rds")
results1 <- readRDS("data/GompertzBigUnitRL3.rds")
results2 <- readRDS("data/GompertzHugeRL3.rds")

resultsBig <- dplyr::bind_rows(results1, results2) %>% 
  filter(N == 50)

KF <- results0 %>%
  filter(algorithm == "KF")

IF <- results0 %>%
  filter(algorithm == "IF")

fct_orders <- paste(
  rep(c("U = 5", "U = 15", "U = 50", "U = 100"), each = 4),
  rep(c("N = 20", "N = 50", "N = 100", "N = 200"))
)

IF %>%
  pivot_longer(
    cols = starts_with("ll_"),
    names_to = "iter",
    values_to = "loglik",
    names_prefix = "ll_"
  ) %>%
  mutate(
    n_obs = paste0("N = ", N),
    n_units = paste0("U = ", U)
  ) -> IF_long

KF_max <- KF %>%
  filter(N == 50) %>% 
  mutate(
    n_obs = paste0("N = ", N),
    n_units = paste0("U = ", U)
  ) %>%
  select(-COOLING_TYPE, -J, -M, -BLOCK, -COOLING, -(ll_2:ll_50)) %>%
  rename(ll_max = ll_1) %>%
  group_by(n_units, seed = data_seed) %>%
  summarize(
    ll_max = max(ll_max),
    ll_min = min(ll_max)
  ) %>% 
  mutate(n_units = factor(n_units, levels = c('U = 5', 'U = 15', 'U = 50', 'U = 100')))


fct_orders <- paste(
  rep(c("U = 200", "U = 500", "U = 1000", "U = 2500"))
)

resultsBig %>%
  pivot_longer(
    cols = starts_with("ll_"),
    names_to = "iter",
    values_to = "loglik",
    names_prefix = "ll_"
  ) %>%
  mutate(
    n_obs = paste0("N = ", N),
    n_units = paste0("U = ", U),
    n_units = factor(n_units, levels = fct_orders)
  ) -> IF_longBig

IF_long_ntruth <- IF_longBig %>% 
  filter(iter != 'truth') %>% 
  mutate(iter = as.numeric(iter))

IF_truth <- IF_longBig %>% 
  filter(iter == 'truth') %>% 
  select(-iter) %>% 
  mutate(
    n_units = factor(n_units, levels = fct_orders)
  ) %>%
  group_by(n_units) %>% 
  distinct(loglik)
@

\begin{figure}[!ht]
<<gompFig1, fig.height=4>>=
gg_smallU <- IF_long %>%
  filter(J == 1000) %>%
  filter(N == 50) %>%
  group_by(iter, BLOCK, n_units) %>%
  summarize(
    min = quantile(loglik, 0.10),
    # min = min(loglik), 
    median = median(loglik),
    logmeanexp = logmeanexp(loglik),
    mean = mean(loglik),
    max = max(loglik)
  ) %>%
  mutate(
    iter = as.numeric(iter),
    BLOCK = factor(BLOCK, levels = c(TRUE, FALSE)),
    n_units = factor(n_units, levels = c('U = 5', 'U = 15', 'U = 50', 'U = 100'))
  ) %>%
  filter(iter > 0) %>%
  ggplot(aes(x = iter, col = BLOCK)) +
  geom_line(aes(y = max)) +
  geom_segment(aes(y = min, yend = max, xend = iter)) +
  facet_wrap(~n_units, scales = 'free', nrow = 1) +
  theme_bw() +
  geom_hline(data = KF_max, aes(yintercept = ll_max), linetype = 'solid') +
  ylab("log-likelihood") +
  theme(axis.text = element_text(size = 6), legend.position = 'none', axis.title.x = element_blank()) +
  scale_color_manual(name = 'Marginalized', values = MARG_COLS)

gg_bigU <- IF_long_ntruth %>%
  filter(J == 1000) %>%
  filter(N == 50) %>% 
  mutate(n_units = factor(n_units, levels = fct_orders)) %>%
  group_by(iter, BLOCK, n_units) %>%
  summarize(
    min = quantile(loglik, 0.10),
    median = median(loglik),
    logmeanexp = logmeanexp(loglik),
    mean = mean(loglik),
    max = max(loglik)
  ) %>%
  mutate(
    BLOCK = factor(BLOCK, levels = c(TRUE, FALSE))
  ) %>%
  filter(iter > 0) %>%
  ggplot(aes(x = iter, col = BLOCK)) +
  geom_line(aes(y = max)) +
  geom_segment(aes(y = min, yend = max, xend = iter)) +
  facet_wrap(~n_units, scales = 'free', nrow = 1) +
  theme_bw() +
  geom_hline(data = IF_truth, aes(yintercept = loglik), linetype = 'dashed') +
  ylab("log-likelihood") +
  xlab("Iteration number (m)") +
  theme(axis.text = element_text(size = 6), legend.position = 'bottom') +
  scale_color_manual(name = 'Marginalized', values = MARG_COLS)

cowplot::plot_grid(gg_smallU, gg_bigU, nrow = 2, rel_heights = c(0.4, 0.6))
@
\caption[Comparing the MPIF and PIF algorithms for fitting the stochastic Gompertz model.]{\label{fig:gomp}Comparing the MPIF and PIF algorithms for fitting the stochastic Gompertz model.
The solid horizontal line shows the true maximum likelihood, determined via the Kalman filter and a numeric optimizer, an intractable approach for high-dimensional parameter spaces $(U > 100)$; in these cases, the dashed line indicates the likelihood at the data-generating parameters.
Each algorithm used 50 unique starting points.
Vertical bars span the tenth percentile to the maximum likelihood values; lowest values were excluded due to poor likelihoods from the PIF algorithm.}
\end{figure}

\section{Example: Measles in the United Kingdom}\label{sec:UKmeas}

We show how MPIF and PIF compare in an epidemiological model for weekly reported measles cases for 20 different UK cities from 1950 to 1964 \citep{korevaar20}.
Pre-vaccination UK measles data has been used extensively to motivate innovative methods for inference on stochastic processes since \citet{bartlett60}, yet, fitting nonlinear Markov process models simultaneously to multiple cities with shared and unit-specific parameters remains a challenge, leading practitioners to consider linearizations that have uncertain consequences \citep{korevaar20}.
We fit three different models to the data, all based on the susceptible-exposed-infectious-recovered (SEIR) model of \citet{he10}. 
The state process, $X_u(t)=\big(S^{(u)}_t,E^{(u)}_t, I^{(u)}_t, R^{(u)}_t\big)$, tracks the number of susceptible, exposed, infected and recovered individuals in each unit, $u$. 
The total population size, $\pop^{(u)}(t)$, is treated as known, interpolated from census data using cubic splines, and we use this constraint to avoid explicit specification of $R^{(u)}_t$.
State transitions are generated using an Euler approximation to a continuous-time Markov chain, with time step $\eulerstep=1$ day, as follows:
\begin{align*}
A^{(u)}_{BS, t} &\sim \text{Pois}\big(\mu^{(u)}_{BS}(t)\, \eulerstep\big)
\\
(A^{(u)}_{SE, t},A^{(u)}_{SD, t}) &\sim \text{Eulermultinom}\Big(S^{(u)}_t, \bar{\mu}^{(u)}_{SE}(t)\big(\Gamma^{(u)}(t + \eulerstep) - \Gamma(t)\big)/\eulerstep, \mu^{(u)}_{SD}, \eulerstep \Big)
\\
(A^{(u)}_{EI, t},A^{(u)}_{ED, t}) &\sim \text{Eulermultinom}\big(E^{(u)}_t, \mu^{(u)}_{EI}(t), \mu^{(u)}_{ED},\eulerstep\big)
\\
(A^{(u)}_{IR, t},A^{(u)}_{ID, t}) &\sim \text{Eulermultinom}\big(I^{(u)}_t, \mu^{(u)}_{IR}(t), \mu^{(u)}_{ID}, \eulerstep\big),
\\
S^{(u)}_{t+\eulerstep} &= S^{(u)}_t + A^{(u)}_{BS, t} - A^{(u)}_{SE, t} - A^{(u)}_{SD, t}, 
\\
E^{(u)}_{t+\eulerstep} &= E^{(u)}_t + A^{(u)}_{SE, t} - A^{(u)}_{EI, t} - A^{(u)}_{ED, t}, 
\\
I^{(u)}_{t+\eulerstep} &= I^{(u)}_t + A^{(u)}_{EI, t} - A^{(u)}_{IR, t} - A^{(u)}_{ID, t}. 
\end{align*}
Here, $A^{(u)}_{BC,t}$ counts transitions from compartment $B$ into $C$ for unit $u$ between time $t$ and $t+\eulerstep$,  $\text{Pois}(\lambda)$ is a Poisson distribution with mean $\lambda$, $\Gamma^{(u)}(t)$ is a gamma process with mean $t$ and intensity $\sigma^{(u)}_{SE}$ \citep{breto09}, and $\text{Eulermultinom}(n, \mu_1,\mu_2,\eulerstep)$ is a multinomial distribution with $n$ independent trials and event probabilities given by $p_0 = \exp\big\{ -(\mu_1 + \mu_2)\eulerstep \big\}$ and $p_i = \frac{\mu_i}{\mu_1+\mu_2}\big(1-p_0\big)$.
The Eulermultinom outcome is the number of events of type $p_1$ and $p_2$, which correspond to transitions out of the source compartment.
The remaining events, of type $p_0$, correspond to individuals remaining in the source compartment.
The rate of arrivals into the susceptible class, $\mu^{(u)}_{BS}(t)$, is given by
\begin{align*}
	\mu^{(u)}_{BS}(t) = &\big( 1-c^{(u)} \big) \, b^{(u)}(t- \tau_d) +
	  c^{(u)} \, \delta\big( (t-\tau_c) \text{ mod } \tau_y\big)
	    \int^t_{t-\tau_y}b^{(u)}(t- \tau_d -s)\, ds,
\end{align*}
where $\delta$ is the Dirac delta function, $b^{(u)}(t)$ is the births per year at time $t$ interpolated from annual data using cubic splines, $\tau_d$ is the delay in transitions from $B$ to $S$, $\tau_y = 1$ year, and $\tau_c$ is the school admission day, i.e., the 251st day of the year. 
We set $\tau_d = 4$ years to describe the age at which individuals typically enter a high-transmission environment.

The rate at which individuals enter state $E$ is $\mu^{(u)}_{SE}(t) = \bar{\mu}^{(u)}_{SE}(t) \, \frac{d\Gamma^{(u)}(t)}{dt}$, where $\bar{\mu}^{(u)}_{SE}(t)$ is the mean rate given by
$
  \bar{\mu}^{(u)}_{SE}(t) =
    \frac{
      \beta^{(u)}(t)\, \big(I^{(u)}_t+\iota^{(u)}\big)
    }{
      \pop^{(u)}(t)
    },
$
where $\pop^{(u)}(t)$ is the city population at time $t$ interpolated from annual data, and $\iota^{(u)}$ is the average number of infected individuals visiting the city at any time. 
The force of infection, $\beta^{(u)}(t)$, is given by
\begin{align*}
	&\beta^{(u)}(t) = \begin{cases}
		\beta^{(u)}_0 \big( 1+a^{(u)}(1-p)/p \big) & \text{during school term}\\
		\beta^{(u)}_0 \big( 1-a^{(u)} \big) & \text{during vacation}\\
	\end{cases}\\
  &\beta^{(u)}_0 = R^{(u)}_0\big( 1-\exp\big\{ -(\mu^{(u)}_{IR}(t)+\mu^{(u)}_{ID})\Delta\big\}\big)/\Delta.
\end{align*}
where $p = 0.7589$ is the proportion of the year occupied by the school term.
The remaining transition rates are assumed to be constant: $\mu^{(u)}_{EI}(t) = \sigma^{(u)}$, $\mu^{(u)}_{IR}(t) = \gamma^{(u)}$, and $\mu^{(u)}_{SD} = \mu^{(u)}_{ED} = \mu^{(u)}_{ID} = 0.02 \, \text{yr}^{-1}$.
Lastly, we follow \citet{he10} by using a discretized normal distribution for the number of cases reported: 
\begin{align*}
 P\big(Y^{(u)}_n = y^{(u)} \big| Z^{(u)}_n = z^{(u)} \big) =
   \Phi\big(y^{(u)} + 0.5, \rho^{(u)} z^{(u)}, \rho^{(u)}(1-\rho^{(u)})z^{(u)} +
     [\psi^{(u)} \, \rho^{(u)} \, z^{(u)}]^2 \big)\\
   \qquad - \Phi\big( y^{(u)} - 0.5, \rho^{(u)} z^{(u)}, \rho^{(u)}(1-\rho^{(u)})z^{(u)} +
     [\psi^{(u)}\, \rho^{(u)}\, z^{(u)}]^2 \big)
\end{align*}
where $\Phi(\cdot;\mu, \sigma^2)$ is the CDF for a $\normal[\mu,\sigma^2]$ random variable and $Z_n$ is the number of people transitioning from $I$ to $R$ between the $(n-1)th$ and $n$th observation times. 
We use three different models based on the \cite{he10} model, with the key difference of investigating subsets of the parameters that might be well modeled as shared.
\begin{enumerate}
  \item The ``$c$-shared" model uses a shared parameter for $c$.
  \item The ``$\iota$-shared" model uses a log-log linear model between $\iota$ and the city population for year 1950, specifically $\log\big(\iota^{(u)}\big) = \iota_1 + \iota_2 \cdot \log\big(\pop^{(u)}(1950)\big)$.
  \item The ``7-shared" model uses the log-log linear model for $\iota$ and shared parameters for $c$, $R_0$, $\gamma$, $\sigma$, $\sigma_{SE}$, and $a$.
\end{enumerate}

For each model, we run MPIF and PIF for 200 iterations, each search starting from one of 36 different parameter vectors randomly sampled from a hypercube where each dimension is slightly larger than the range spanned by the corresponding unit-specific MLE's in \cite{he10}. 
We perform these searches using 500, 5000, and 10000 particles to discern how the fits yielded by MPIF and PIF differ based on the selected particle count. 
For the present data set, 500 particles is too low for proper optimization, 5000 is adequate, and 10000 enables a thorough parameter search. 
The log-likelihood for each fit is evaluated using the average of replicated particle filter evaluations with 10000 particles at evenly-spaced iterations: 20, 56, 92, 128, 164, and 200. 
Figure~\ref{fig:measles1} summarizes the output of this Monte Carlo optimization search. 
As with the simulation study involving the Gompertz population model, the MPIF algorithm consistently yields parameter estimates corresponding to higher likelihoods than the PIF algorithm. 

<<loadMeasles>>=
# Load results
results_in = pomp::bake("data/measles.rds",{
  # AA: Full results are excluded from repo due to being ~1 GB. Let me know if
  # this is an issue.
  RESULTS_PATH = "mpif_example"
  results_in = gather_results(
    file_names = "fit_results_out.rds",
    parent_dir = RESULTS_PATH
  )
  results_in |>
    mutate(
      np_fitr = stringr::str_extract(path, "np_[0-9]+") |>
        stringr::str_extract("[0-9]+") |>
        as.numeric(),
      model = stringr::str_extract(path, "/+[a-zA-Z]+/np") |>
        stringr::str_extract("/[a-zA-Z]+/") |>
        stringr::str_extract("[a-zA-Z]+"),
      algorithm = stringr::str_extract(path, "np_[0-9]+/+[a-zA-Z]+/") |>
        stringr::str_extract("/[a-zA-Z]+/") |>
        stringr::str_extract("[a-zA-Z]+"),
      eval_iter = stringr::str_extract(path, "iter_[0-9]+") |>
        stringr::str_extract("[0-9]+") |>
        as.numeric()
    ) |>
    mutate(eval_iter = ifelse(is.na(eval_iter), 200, eval_iter))
})
@

In practice, because iterated filtering algorithms are stochastic optimization algorithms, many Monte Carlo replicates are conducted from various initialization points, and final parameter estimates correspond to the search with the highest likelihood. 
Because of this, we are primarily interested in how in the maximum estimate from each algorithm compares. 
In Figure~\ref{fig:measles1}, we note that MPIF consistently yields larger sample maximums of the log-likelihood evaluations irrespective of the model or particle count we use. 
By 200 iterations, we see that maximum log-likelihoods obtained using MPIF are 70 to 105 units higher than PIF for the $\iota$-shared and $c$-shared models, or about 4 to 5 units per city. 
MPIF has about half the advantage for the 7-shared model by 200 iterations. 

Close inspection of the results show that for nearly all combinations of number of particles, iterations, and model specification, the MPIF algorithm outperforms the PIF algorithm. 
However, in Figure~\ref{fig:measles1}, we can see that at the 20 and 56 iteration evaluations, the maximum obtained likelihood for the 7-shared model fit with 5000 particles is higher for the PIF algorithm than MPIF.   
Here, the distribution for PIF-generated log-likelihoods at these iterations have especially long right-tails, suggesting that PIF's observed advantage in this case is a result of large variance working in its favor.
As the number of iterations increases, the spread of the MPIF and PIF log-likelihoods decreases and MPIF consistently yields higher log-likelihoods. 
Increasing the number of particles also reduces the variance among Monte Carlo replications, and when the number of particles ($J$) is largest, the advantage of MPIF over PIF becomes more evident for all models variations. 

The boxplots in Figure~\ref{fig:measles1} also demonstrate that the log-likelihood standard deviation is consistently lower for MPIF when a sufficient number of particles are used. 
In addition to suggesting that even poor performing Monte Carlo replicates of the MPIF algorithm still correspond to better outcomes than the best replicates for the PIF algorithm, this feature is useful in practice as the convergence of iterated filtering algorithms to the MLE is often judged by whether or not distinct Monte Carlo replicates finish at the same maximum, within suitable Monte Carlo error. 
In particular, reducing the variance between Monte Carlo replicates results in tighter confidence intervals when computing Monte Carlo adjusted profile confidence intervals \citep{ionides17}. 

\begin{figure}[!ht]
<<figmeasles1, fig.align='center', fig.height=4.5, fig.width=7>>=
library(grid)
library(gtable)

gg <- results_in |>
  mutate(algorithm = ifelse(algorithm == 'mpif', TRUE, FALSE)) |> 
  mutate(algorithm = factor(algorithm, levels = c(TRUE, FALSE)),
         np_fitr = factor(np_fitr, levels = c(10000, 5000, 500)),
         model = factor(model, levels = c('many', 'iota', 'cohort'))) |> 
  ggplot(
    mapping = aes(
      x = eval_iter, 
      y = total_ll, 
      group = interaction(eval_iter, algorithm, model, drop = TRUE),
      color = algorithm
    )
  ) +
  geom_vline(data = NULL, xintercept = unique(results_in$eval_iter), linetype = 'longdash', col = 'grey70') +
  geom_boxplot(width = 20, linewidth = 0.4, outlier.size = 0.75) +
  xlab("Iteration (m)") +
  ylab("log-likelihood") +
  scale_color_manual(name = "Marginalized", values = MARG_COLS) + 
  facet_grid(np_fitr~model, labeller = as_labeller(
     c(
      cohort = "Model: c-shared", 
      iota = "Model: iota-shared", 
      many = "Model: 7-shared",
      `10000` = "J = 10000",
      `500` = "J = 500",
      `5000` = "J = 5000"
    )), scales = 'free_y', drop = TRUE) + 
  ggh4x::facetted_pos_scales(y = list(
    scale_y_continuous(limits = c(-41250, -40260)), 
    scale_y_continuous(limits = c(-41250, -40260)),
    scale_y_continuous(limits = c(-42500, -40260))
  ))

# CREDIT FOR CODE TO REMOVE UNUSED FACET COMBOS: https://stackoverflow.com/questions/49521848/remove-unused-facet-combinations-in-2-way-facet-grid

print(gg)
@
\caption[Comparing the MPIF and PIF algorithms using a mechanistic model for measles.]{\label{fig:measles1} 
Comparing the MPIF and PIF algorithms using a mechanistic model for measles.
Rows correspond to a different number of particles $J$ used in Algorithm~\ref{alg:mpif}. 
The log-likelihood is evaluated at iterations 20, 56, 92, 128, 164, and 200, marked by vertical grey lines.}
\end{figure}


\section{Discussion}\label{sec:mpifdiscussion}

The issue of particle depletion when estimating the posterior distribution of parameter values using a particle filter has previously been noted \citep[e.g.,][Section~1.2]{chen24}. 
A key innovation of iterated filtering algorithms is that adding parameter perturbations helps revive the particle representations from a depleted state by adding artificial noise to the parameter particles. 
These perturbations are precisely why the number of unique particles representing the distribution of $\Psi_1$ in Panel~A of Figure~\ref{fig:depletion} does not degenerate to zero over time.
Given this observation, an alternative approach to solving the particle depletion issue that arises in higher dimensions would be to perturb all model parameters at each time-step. 
This approach is supported by Theorem~\ref{theorem:pif}, and avoids the analytic challenges associated with adding the marginalization step.
However, perturbing all model parameters at each step is equivalent to applying a vanilla iterated filtering algorithm to a PanelPOMP model, which generally performs worse on panel models than the PIF variation \citep{breto20}.

\citet{liuwest01} note that the artificial noise introduced from parameter perturbations results in loss of information.
This loss of information motivates the common practice in applications of iterated filtering of only perturbing model parameters when the data used to calculate the particle weights has direct relation with the parameters that are being perturbed.
For instance, it is common practice to only perturb parameters that are unique to the initialization density $f_{X_{u, 0}}(x_{u, 0};\, \theta)$ at the first available observations, as these observations have the strongest signal for the initialization parameters. 
If initial parameters are perturbed at all observation times, then the signal from these initial observations gets lost over time. 
This same principle serves as a motivator for the PIF algorithm and describes why PIF is more successful than vanilla iterated filtering algorithms applied to PanelPOMPs: perturbing unit-specific parameters while considering data from other units results in a significant loss of information.

Therefore despite having theoretical guarantees, the challenge of iterating filtering for PanelPOMP models can be described as a tradeoff between particle depletion and a loss of signal due to parameter perturbations. 
The MPIF algorithm introduced here is designed to address both of these challenges simultaneously by avoiding perturbations when the signal is weak, but not resampling unit-specific parameters using weights calculated with data from other units. 
The cost of this modification is a small amount of bias for the particle representation of the posterior distribution at each step. 
Theorem~\ref{theorem:GG} formally demonstrates that the affect of the bias can be completely negated if the log-likelihood is quadratic, which is the limiting behavior of all likelihood surfaces.

Finally, Theorem~\ref{theorem:pif} does provide some stronger guarantees for MPIF under additional constraints on the PanelPOMP model that we have not yet mentioned. 
In a model with only unit-specific parameters ($\Phi = \emptyset$), for instance, MPIF is equivalent to conducting IF2 independently on each unit, and therefore the convergence results of Theorem~\ref{theorem:pif} apply. 
Similarly, if the model only contains shared parameters ($\Psi_{1:U} = \emptyset$), then MPIF is equivalent to PIF, and once again stronger theoretical guarantees are available. 
This equivalency also provides some intuition as to when MPIF will outperform its alternatives. 
In a model consisting primarily of shared parameters, MPIF behaves very similarly to PIF and adds a smaller advantage relative to the case when there are more unit-specific parameters. 
We have seen this pattern in our results, as the gain in log-likelihood obtained via MPIF was smallest for the measles model with only one unit specific parameter.
